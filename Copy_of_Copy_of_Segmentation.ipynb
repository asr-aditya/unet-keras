{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIXSjk21OYev"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u7vIbl2qlk3-",
    "outputId": "9cd3d846-9e0a-4adb-d736-71335e1536b7"
   },
   "outputs": [],
   "source": [
    "#%cd drive/My Drive/Intern/Image_Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4AP2fXaWmKPs",
    "outputId": "48060a6e-3148-46a1-878a-9317c386942c"
   },
   "outputs": [],
   "source": [
    "#%cd unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfhL_6nAqJtY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeZY172JP00Z"
   },
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hXmXi65TUFk"
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lX3kCwy9Mzme"
   },
   "outputs": [],
   "source": [
    "def gen(train_path ,image_folder = 'image', mask_folder = 'label',image_color_mode = \"grayscale\",\n",
    "        mask_color_mode = \"grayscale\", target_size = (256,256), flag_multi_class = False, batch_size = 2,data_gen_args=data_gen_args\n",
    "       ):\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img,mask) in train_generator:\n",
    "        print(\"Loading gene\")\n",
    "        if(np.max(img) > 1):\n",
    "            img = img / 255\n",
    "            mask = mask /255\n",
    "            mask[mask > 0.5] = 1\n",
    "            mask[mask <= 0.5] = 0\n",
    "            yield(img, mask)\n",
    "\n",
    "#     return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image gen\n",
      "Found 30 images belonging to 1 classes.\n",
      "loading mask gen\n",
      "Found 30 images belonging to 1 classes.\n",
      "adjusting image\n"
     ]
    }
   ],
   "source": [
    "import medicalai as ai\n",
    "datasetFolderPath = 'data/membrane/'\n",
    "(IMG_HEIGHT,IMG_WIDTH) = (256,256)\n",
    "augment = ai.AUGMENTATION(rotation_range = 12, \n",
    "                          fill_mode='nearest', \n",
    "                          width_shift_range=0.1, \n",
    "                          height_shift_range=0.1, \n",
    "                          brightness_range = (0.9, 1.1), \n",
    "                          zoom_range=(0.85, 1.15), \n",
    "                          rescale= 1./255,)\n",
    "dsHandler = ai.segmentaionGenerator(folder=datasetFolderPath,targetDim=(IMG_HEIGHT,IMG_WIDTH), \n",
    "                                        augmentation=augment, class_mode=None,\n",
    "                                        batch_size = 1,color_mode=\"grayscale\",\n",
    "                                        image_folder_name = \"image\", mask_folder_name = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAKzlg1bUbS0"
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "q-AN18E9nlR3",
    "outputId": "7fc90608-8b67-4450-90e2-d1946ae4b9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Loading gene\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D40096DC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D40096DC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7536 - accuracy: 0.1949\n",
      "Epoch 00001: loss improved from inf to 0.75356, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7536 - accuracy: 0.1949\n",
      "Epoch 2/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.8016\n",
      "Epoch 00002: loss improved from 0.75356 to 0.69315, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6932 - accuracy: 0.8016\n",
      "Epoch 3/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.7914\n",
      "Epoch 00003: loss improved from 0.69315 to 0.69303, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6930 - accuracy: 0.7914\n",
      "Epoch 4/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.7631\n",
      "Epoch 00004: loss improved from 0.69303 to 0.69290, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6929 - accuracy: 0.7631\n",
      "Epoch 5/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7849\n",
      "Epoch 00005: loss improved from 0.69290 to 0.69229, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6923 - accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.7516\n",
      "Epoch 00006: loss improved from 0.69229 to 0.69215, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6921 - accuracy: 0.7516\n",
      "Epoch 7/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.7471\n",
      "Epoch 00007: loss did not improve from 0.69215\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.7471\n",
      "Epoch 8/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.8065\n",
      "Epoch 00008: loss improved from 0.69215 to 0.69162, saving model to unet_membrane.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6916 - accuracy: 0.8065\n",
      "Epoch 9/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7873\n",
      "Epoch 00009: loss did not improve from 0.69162\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.7873\n",
      "Epoch 10/10\n",
      "Loading gene\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.7638\n",
      "Epoch 00010: loss did not improve from 0.69162\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.7638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d40096a9b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#myGene = gen(train_path = 'data/membrane/train')\n",
    "\n",
    "#myGene = dsHandler.load_generator()\n",
    "\n",
    "myGene = ai.segmentGen(train_path = 'data/membrane/train').load_gen()\n",
    "model.fit( myGene,steps_per_epoch=1,epochs=10,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9DF2_HwoOlM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3ef509a3cc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestGene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/membrane/test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unet_membrane.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestGene\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msaveResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "testGene = testGenerator(\"data/membrane/test\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_membrane.hdf5\")\n",
    "results = model.predict_generator(testGene,30,verbose=1)\n",
    "saveResult(\"results\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Segmentation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
